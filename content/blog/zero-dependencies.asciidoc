---
title: "Why Libraries Should Have No¬π Dependencies"
date: 2022-11-19T18:55:00+01:00
draft: false
markup: adoc
---
:source-highlighter: rouge
:rouge-style: base16.dark
:icons: font
:imagesdir: /images
ifdef::env-github[]
:imagesdir: ../../static/images
endif::[]

== ¬π Terms and Conditions Apply

When you go to a party, social convention suggests that you adhere to the rules and customs of the party host;
for instance, you wouldn't pack out your own food (unless you have a very good reason for doing so, like a food allergy),
just as you wouldn't bring along additional guests which actually hadn't been invited.
After all, if just five people did that and brought five additional guests along, we'd already have 25 people,
and things could easily become messy.
And nobody likes things to become messy, right?

As the author of a software library, you're in a similar situation like a person invited to a party (an actual application):
you should abide by the rules of the host (the application developer),
and for instance not use your own specific logger implementation.
You also should avoid to bring additional guests, i.e. (transitive) dependencies, as much as possible.

<!--more-->

When I shared that line of thinking on Twitter a few weeks back,
this sparked quite an intensive discussion, which I hadn't really expected in that form:

++++
<div align="center">
<blockquote class="twitter-tweet" data-dnt="true"><p lang="en" dir="ltr">I wish more library maintainers would follow a (close to) zero dependencies policy. Libs should never depend on stuff like Guava, kotlin-stdlib, or logger implementations. Yes, it means less comfort for yourself, but your users will be grateful.</p>&mdash; Gunnar Morling üåç (@gunnarmorling) <a href="https://twitter.com/gunnarmorling/status/1474053962034782212?ref_src=twsrc%5Etfw">December 23, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 
</div>
++++

Many folks agreed to that sentiment,
while others said "It depends" (yeah, ok, but where's the fun in stating the obvious?),
made insightful dissenting remarks (which is awesome, always loving to learn from other perspectives),
or even https://twitter.com/JakeWharton/status/1474376582156681217[accused me of hypocrisy] (seriously?!).
So I thought I'd expand a bit on the "No Dependencies for Libraries" paradigm and why I think it's a desirable goal.
First of all, I made that comment in the context of my personal work experience and context,
which primarily is Java-based middleware and backend systems.
Things surely look different in ecosystems without a strong standard library (say, JavaScript),
where you hardly have a choice other than working with additional dependencies.
Similarly, Kotlin is - as I learned - ubiquitous in Android application development nowadays,
so relying on it may represent no problem whatsoever in this particular contex.
Secondly, as with all such design ideas, it's an _aspirational_ goal, a northstar principle, but not an absolute rule to blindly follow under all circumstances.

With that out of the way, let's dive into why I think library authors should aim to minimize their dependencies.
To me, it boils down to three aspects: version conflicts, overhead, and security implications.
Let's discuss each of them a bit more.

== Version Conflicts

The main reason for avoiding or at least minimizing the number of dependencies of a library is the potential for version conflicts with the dependencies of other libraries,
also known as "diamond dependency problem", or just https://en.wikipedia.org/wiki/Dependency_hell["dependency hell"]:

TODO Image

In applications with a flat class (or module) path,
only one version of each class can exist.
If two direct dependencies of an application each depend on a different version of a third dependency,
one version will be chosen (e.g. the newer one),
which may cause issues with that dependency relying on the other version.
The result being notorious errors such as `NoSuchMethodError` when the JVM fails to find a method at runtime which was present at compile time of one of the dependencies.

Now module systems like Java's built-in one, JBoss Modules, or OSGi provide a solution to that problem by loading multiple versions of a library via separate class-loaders.
For instance, the https://github.com/moditect/layrry[Layrry] project provides this capability in an easy-to-use way based on the Java Module System.
But such a solution isn't something you as a library author could rely on,
your users may or may not make use of them.
Worse, also with a module system and its support for loading multiple versions of one library, version conflicts still can arise.
This is the case when the types of a dependency are exported via the public API signatures of another library,
resulting in ugly ``ClassCastException``s at runtime.

check whether compat is a concern
check number of transitive deps yourself

== Overhead

* licenses
* distribution size
* classes loaded
* language runtimes

== Security Implications



== Exceptions

Now let's discuss a few exceptions to the "no dependencies" rule.
A first one are test dependencies;
for tests, you are in control of the class path, i.e. you're in the role of the party host and it's your decision whom to invite, and whom not.
This means, you generally are free to add any dependencies which prove useful for your testing purposes,
for instance I don't see any issue with adding Guava in `test` scope of a Maven project.

On a tangent, I also enjoy using the latest and greatest Java versions for my tests:
while sticking to compatibility with older versions in the main code (which ends up in the published library),
so as to increase the potential audience of a library,
using newer versions in tests allows me to benefit from all the latest goodness such as text blocks or record types.
With the right  link:/blog/using-java-13-text-blocks-for-tests/[build tool configuration],
such combined set-up works great in practice.

The next exception is, again, related to security.
When it comes to aspects like cryptography which have a very high algorithmic complexity and where getting one small detail can prove fatal,
you definitely should rely on the work of domain experts.
Established libraries in these areas are not only created by folks deeply familiar with the subject matter,
but usually also are peer-reviewed or even audited by other experts and proven in the field.
_Don't build your own encryption!_

Another reason for establishing dependencies in a library is if your own library is an "enabler" or "integration" dependency.
That's the case for Quarkus extensions for instance;
their purpose is to integrate 3rd party dependencies into the Quarkus and GraalVM ecosystem,
e.g. by providing substituations for using these dependencies in GraalVM native binaries.
In that case, transitively pulling in a specific 3rd party dependency is the very purpose of such an extension and of course it's fine to establish that dependency.

A related category are "umbrella" dependencies for libraries which are split into multiple fine-grained modules.
One example would be the https://mvnrepository.com/artifact/io.netty/netty-all["Netty All" JAR] whose job it is to bring in all the different Netty modules,
which can make life a bit easier if you depend on many of them.

From a more general point of view,
it always comes down to a trade-off between the value which a given dependency provides,
and the price that needs to be paid for its usage in terms of the aforementioned criteria.
In that light, depending on a special-purpose library such as JCTools can be a very reasonable decision for a library author;
it provides a high value in form of concurrency data structures which can make huge impact on performance and which will be hard to get right yourself.
And looking at it in terms of dependencies, it has a very low cost: with exactly zero dependencies,
you end up pulling in JCTools and nothing more,
also JCTools itself is developed with a strong focus on backwards compatibility.

On the other hand, depending on a general-purpose library such as Google's Guava typically isn't a good idea for libraries.
Note this is not to say that these libraries don't provide great value, on the contrary.
But in many cases, authors are just after a few selected utility classes or convinience methods,
for which pulling in a large dependency isn't really worth the potential trouble.
In any case, you should take a close look at a project's versioning policies before making any decision.
Guava as an example used to introduce frequent breaking changes,
which resulted in quite a bad reputation unfortunately.
Since then, it's authors https://twitter.com/kevinb9n/status/1514641920156311563[took a different stance] on compatibility,
but libraries transitively depending on older Guava versions may still expose diamond version problems.

== Mitigation

Assuming there's a high-value dependency which really, really would be beneficial as a dependency of your own library,
how should you go about establishing that dependency?

First of all, do your due diligence by answering questions like the following:

* How many dependencies does that library itself have
(ideally, none)?
* What is its track record in terms of API evolution and compatibility?
* Is it known to be changed in a careful way without breaking changes,
or are new versions likely to introduce incompatible API changes, thus introducing the odds for problems in case of version collisions?
* Does it have an explicit and well-defined API to begin with?
* Does it provide a high value to you,
which you couldn't otherwise get?

If after answering all these questions you feel like adding that dependency to your own library makes sense,
the most obvious option would be to declare it as a dependency in the metadata descriptor of your library, for instance the _pom.xml_ file if you're using Maven.

In terms of which version to depend on,
trying to be as conservative as possible can be a useful strategy.
If for instance you know that version 1.0 of some dependency is enough for your own purposes,
also if there's a newer version 2.0,
declaring the dependency to 1.0 can make sense to signal to clients that they don't necessarily need to upgrade to 2.0 themselves yet
(one reason could for instance be compatibility with older Java versions in the earlier version of that dependency).
Better even,
test against a range of versions (e.g. 1.0 and 2.0 of said library),
and document all the versions your library is compatible with.
That is for instance what https://cowtowncoder.medium.com/jackson-guava-compatibility-b0b61ac59b28[Jackson does] for it's Guava datatype support module.

Another option popular amongst some library authors is _shading_ external dependencies into their own artifacts:
a copy of the classes is created within the package namespace of your own library,
and all your library's byte code referencing any of these types is rewritten in a build processing step accordingly.
While this sounds tempting for avoiding any version conflicts,
shading isn't without its problems:

* It effectively means you take ownership of that code; in case of any bugs or security issues,
users of your library can't simply update the transitive dependency,
but rely on you to release a new version, shading the fixed version of the dependency.
Thus you should closely track the dependency's releases and in particular any CVEs which are reported against it.
* It leads to multiple versions of the same classes being present in applications
(for instance, look for the number of shaded ASM versions in a typical enterprise application or microservice),
increasing artifact size and memory consumption; worse, if the dependency classes are exposed on public interfaces,
shading guarantees a conflict, as the different shaded versions are incompatible with each other by definition
* It requires thorough testing to make sure everything works as intended, for instance when loading classes from the dependency via reflection, which may cause them to be missed during the shading process

If you want to go down the shading route, I'd suggest to only shade in the minimal set of required classes,
using tools such as https://www.guardsquare.com/proguard[ProGuard].
That way, you'll at least be off the hook when there's issues in parts of the dependency which you haven't shaded.

Yet another option is copying the relevant parts of the source code of the dependency into your own code base.
That can be attractive if you're just after some small part of the functionality provided by a dependency,
say a handful of helper methods.
Even more than with shading, you're responsible now for that code,
i.e. it's only really an option if you have the capability and bandwidth to maintain it going forward.
As you have created a fork that way, you'll be cut off from any future improvements or bug fixes to the original code.
Also make sure the license of the code is compatible with the one of your own library.
Under the right circumstances, this can be a great strategy,
which we for instance employed within the Hibernate Validator project,
where we decided to pull in the source code of the ClassMate library and maintained it ourselves going forward.



depencency types types in signatures
explicitly define API